{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTbi27k1HpK_",
    "outputId": "d6604d63-4c80-4e94-bc5e-0fd21c06afe3"
   },
   "outputs": [],
   "source": [
    "!pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceIAPjMZHqKk"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KE1wybF-Hw52",
    "outputId": "b5a7758b-cb0a-41a6-f69e-996d7513ddb7"
   },
   "outputs": [],
   "source": [
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8hZrliVHzSQ"
   },
   "outputs": [],
   "source": [
    "data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEARCH_TRIALS = 10\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "print(\"CHANNELS:\", n_channels)\n",
    "print(\"CLASSES:\", n_classes)\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "print(DataClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBmLDDJ6IQRf"
   },
   "source": [
    "## First, we read the MedMNIST data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8YDE74iICr1",
    "outputId": "ec831ede-4dc4-4710-b51e-dbe3fbc1d120"
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "   # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                # transforms.RandomRotation(30),\n",
    "                                # transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5],[0.5])])\n",
    "\n",
    "\n",
    "\n",
    "# Load the original dataset\n",
    "original_dataset = medmnist.dataset.BreastMNIST(split='train', transform=data_transform, download=download)\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=train_transforms, download=download)\n",
    "validation_dataset = DataClass(split='val', transform=validation_transforms, download=download)\n",
    "test_dataset = DataClass(split='test', transform=test_transforms, download=download)\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = data.DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AKwZjufIFSE",
    "outputId": "62e3404d-0088-4a99-da73-5960bafa23ed"
   },
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(\"===================\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "zgYO03A9IHy0",
    "outputId": "03637f3b-10c1-4431-d4d7-aac632f0ddd6"
   },
   "outputs": [],
   "source": [
    "# montage\n",
    "\n",
    "original_dataset.montage(length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EK19eUaIe9n"
   },
   "source": [
    "## Then, we define a simple model for illustration, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItUZoM6oIYbD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "class ExtendedNetwork(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        # super(ExtendedNetwork, self).__init__()\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Freeze all layers of the original ResNet18 model\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        # self.resnet.fc = nn.Linear(num_features, 512)\n",
    "\n",
    "\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.BatchNorm1d(512),  # Match the batch norm to the output features of ResNet\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)    # Pass input through ResNet18\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ExtendedNetwork()\n",
    "network.to(device=device)\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    pred = outputs.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(targets.view_as(pred)).sum().item()\n",
    "    return correct / len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftkAQZBGIlvd"
   },
   "source": [
    "## Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna \"ray[tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "LEARNING_RATES = [0.0001, 0.00015, 0.001, 0.0015]\n",
    "MOMENTUM_VALUES = [0.9, 0.92, 0.93, 0.95]\n",
    "WEIGHT_DECAYS = [1e-4, 15e-4, 17e-4, 1e-3]\n",
    "optimizers = [optim.Adagrad, optim.Adam, optim.AdamW, optim.SGD]\n",
    "patiences = [5, 7]\n",
    "schedulers = [torch.optim.lr_scheduler.ReduceLROnPlateau, torch.optim.lr_scheduler.StepLR]\n",
    "loss_functions = [nn.NLLLoss(), nn.CrossEntropyLoss()]\n",
    "\n",
    "hyperparameters_grid = product(LEARNING_RATES, MOMENTUM_VALUES, WEIGHT_DECAYS, optimizers, patiences, schedulers, loss_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer_class, parameters, lr, momentum, weight_decay):\n",
    "    # Check which optimizer is being used and adjust parameters accordingly\n",
    "    if optimizer_class in [optim.SGD]:\n",
    "        # SGD uses both momentum and weight_decay\n",
    "        return optimizer_class(parameters, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer_class in [optim.Adam, optim.AdamW, optim.Adagrad]:\n",
    "        # Adam and AdamW do not use momentum\n",
    "        return optimizer_class(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        # Default fallback for any other optimizers\n",
    "        raise ValueError(f\"Unsupported optimizer class {optimizer_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(scheduler_class, optimizer_class, patience=None):\n",
    "    # Check the type of scheduler to initialize it correctly\n",
    "    if scheduler_class == torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "        # ReduceLROnPlateau requires 'patience' and benefits from a 'factor'\n",
    "        return scheduler_class(optimizer_class, mode='min', patience=patience, factor=0.1, verbose=True)\n",
    "    elif scheduler_class == torch.optim.lr_scheduler.StepLR:\n",
    "        # StepLR does not use 'patience' but uses 'step_size' and 'gamma'\n",
    "        return scheduler_class(optimizer_class, step_size=50, gamma=0.1)\n",
    "    else:\n",
    "        # For other schedulers, adjust as necessary or raise an error\n",
    "        raise ValueError(\"Unsupported scheduler class provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(split):\n",
    "    # Load the model with the best accuracy\n",
    "    network.load_state_dict(torch.load('best_model.pth'))\n",
    "    network.eval()\n",
    "    y_true = torch.tensor([], device=device)\n",
    "    y_score = torch.tensor([], device=device)\n",
    "    collected_inputs = torch.tensor([], device=device)\n",
    "    collected_targets = torch.tensor([], device=device)\n",
    "\n",
    "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = network(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1).squeeze()\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "            collected_inputs = torch.cat((collected_inputs, inputs), 0)\n",
    "            collected_targets = torch.cat((collected_targets, targets), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.cpu().detach().numpy()\n",
    "        collected_inputs = collected_inputs.cpu()\n",
    "        collected_targets = collected_targets.cpu()\n",
    "\n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "\n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "        return metrics, collected_inputs, collected_targets, y_true, y_score\n",
    "\n",
    "# print('==> Evaluating ...')\n",
    "# train_inputs, train_targets, train_true, train_scores = test('train')\n",
    "# test_inputs, test_targets, test_true, test_scores = test('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # Sets the seed for all GPUs\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.nn.functional import log_softmax\n",
    "import logging\n",
    "\n",
    "# Hyperparameters\n",
    "# LEARNING_RATES = [0.0001, 0.001, 0.01]\n",
    "# MOMENTUM_VALUES = [0.9, 0.92, 0.93]\n",
    "# WEIGHT_DECAYS = [0.0001, 0.001, 0.01]\n",
    "PATIENCE = 7  # Patience for early stopping\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "network.to(device)\n",
    "\n",
    "# Prepare grid search\n",
    "hyperparameters_grid = product(LEARNING_RATES, MOMENTUM_VALUES, WEIGHT_DECAYS, optimizers, patiences, schedulers, loss_functions)\n",
    "combination_number = len(LEARNING_RATES) * len(MOMENTUM_VALUES) * len(WEIGHT_DECAYS) * len(optimizers) * len(patiences) * len(schedulers) * len(loss_functions)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Trial', 'AUC', 'Accuracy', 'Learning Rate', 'Momentum', 'Weight Decay', 'Optimizer', 'Patience', 'Scheduler', 'Loss Function'])\n",
    "\n",
    "# Best model tracking\n",
    "best_val_accuracy = 0\n",
    "best_train_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "\n",
    "# Lists to store average accuracy\n",
    "avg_train_accuracies = []\n",
    "avg_val_accuracies = []\n",
    "\n",
    "# Lists to store average losses\n",
    "avg_train_losses = []\n",
    "avg_val_losses = []\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Training and validation\n",
    "for trial, params in enumerate(hyperparameters_grid):\n",
    "    try:\n",
    "        print(f\"\\nTrial {trial + 1}/{combination_number}\")\n",
    "        learning_rates, momentum, weight_decay, optimizer_class, patience, scheduler_class, loss_function = params\n",
    "        # learning_rate = np.random.choice(LEARNING_RATES)\n",
    "        # momentum = np.random.choice(MOMENTUM_VALUES)\n",
    "        # weight_decay = np.random.choice(WEIGHT_DECAYS)\n",
    "\n",
    "\n",
    "        print(f\"Testing on Hyperparameters: Learning Rate: {learning_rates}, Momentum: {momentum}, Weight Decay: {weight_decay}, Optimizer: {optimizer_class}, Patience: {patience}, Scheduler: {scheduler_class}, Loss Function: {loss_function}\")\n",
    "\n",
    "        # # Optimizer setup\n",
    "        # print(f\"Optimizer class type: {optimizer_class}\")\n",
    "        # print(f\"Optimizer class type: {type(optimizer_class)}\")\n",
    "\n",
    "        # optimizer = optim.Adagrad(network.parameters(), lr=learning_rates, weight_decay=weight_decay, maximize=False)\n",
    "        optimizer = get_optimizer(optimizer_class, network.parameters(), learning_rates, momentum, weight_decay)\n",
    "        # scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.2, verbose=True)\n",
    "        scheduler = get_scheduler(scheduler_class, optimizer, patience)\n",
    "\n",
    "        early_stopping_counter = 0\n",
    "        best_epoch_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # Training loop\n",
    "            network.train()\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "            for inputs, targets in tqdm(train_loader, desc=\"(Train) Epoch: \" + str(epoch) + \" on \" + str(device)):\n",
    "                # forward + backward + optimize\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = network(inputs)\n",
    "\n",
    "                targets = targets.squeeze().long()\n",
    "                \n",
    "                if loss_function == nn.NLLLoss():\n",
    "                    outputs = log_softmax(outputs, dim=1)\n",
    "                # Call Loss function\n",
    "                    loss = loss_function(outputs, targets)\n",
    "                else:\n",
    "                    loss = loss_function(outputs, targets)\n",
    "                \n",
    "                # Call backward function\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() #/ len(inputs)\n",
    "                running_accuracy += accuracy(outputs.exp(), targets)\n",
    "\n",
    "            # Train Accuracy calculation\n",
    "            epoch_accuracy = running_accuracy / len(train_loader)\n",
    "            avg_train_accuracies.append(epoch_accuracy)\n",
    "            \n",
    "            # Train Loss calculation\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            avg_train_losses.append(epoch_loss)\n",
    "\n",
    "            print(\"Train - Loss: {:.6f}, Accuracy: {:.2f}%\".format(epoch_loss, running_accuracy / len(train_loader) * 100), \"\\n\")\n",
    "\n",
    "            # Validation\n",
    "            network.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_running_accuracy = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in tqdm(validation_loader, desc=\"(Validation) Epoch: \" + str(epoch) + \" on \" + str(device)):\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "\n",
    "                    val_outputs = network(val_inputs)\n",
    "\n",
    "                    # val_outputs = F.softmax(val_outputs, dim=1)\n",
    "\n",
    "                    val_targets = val_targets.squeeze().long()\n",
    "                    if loss_function == nn.NLLLoss():\n",
    "                        val_outputs = F.log_softmax(val_outputs, dim=1)\n",
    "                        loss = F.nll_loss(val_outputs, val_targets)\n",
    "                        # Call Backward function\n",
    "                        loss.backward()\n",
    "                    else:\n",
    "                        loss = loss_function(val_outputs, val_targets)\n",
    "\n",
    "                    val_running_loss += loss.item()\n",
    "                    val_running_accuracy += accuracy(val_outputs, val_targets)\n",
    "\n",
    "            # Validation Accuracy calculation\n",
    "            val_epoch_accuracy = val_running_accuracy / len(validation_loader)\n",
    "            avg_val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "            # Validation Loss calculation\n",
    "            val_epoch_loss = val_running_loss / len(validation_loader)\n",
    "            avg_val_losses.append(val_epoch_loss)\n",
    "\n",
    "            scheduler.step(val_epoch_loss)\n",
    "\n",
    "            # Early stopping based on validation loss\n",
    "            if val_epoch_loss < best_epoch_val_loss:\n",
    "                best_epoch_val_loss = val_epoch_loss\n",
    "\n",
    "            print(\"Validation - Loss: {:.6f}, Accuracy: {:.2f}%\".format(val_epoch_loss, val_running_accuracy / len(validation_loader) * 100), \"\\n\")\n",
    "\n",
    "            # Check if this trial has the best accuracy\n",
    "            if running_accuracy > best_train_accuracy:\n",
    "                best_train_accuracy = running_accuracy\n",
    "\n",
    "            if val_running_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_running_accuracy\n",
    "                best_hyperparameters = {\n",
    "                    \"learning_rate\": learning_rates,\n",
    "                    \"momentum\": momentum,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"optimizer\": optimizer_class,\n",
    "                    \"patience\": patience,\n",
    "                    \"scheduler\": scheduler_class,\n",
    "                    \"loss_function\": loss_function\n",
    "                }\n",
    "\n",
    "                model_save_path = f\"best_model_seed_{42}.pth\"\n",
    "                torch.save(network.state_dict(), \"best_model.pth\")\n",
    "                print(\"Saved the new best model with seed 42 and validation accuracy of\", best_val_accuracy)  \n",
    "\n",
    "                            # Evaluate the model on test data\n",
    "                test_metrics, _, _, _, _ = test('test')  # Ensure that you have a test_loader defined\n",
    "                test_auc, test_accuracy = test_metrics\n",
    "            \n",
    "                # Create a DataFrame for the new row\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Trial': [trial + 1],\n",
    "                    'AUC': [test_auc],\n",
    "                    'Accuracy': [test_accuracy],\n",
    "                    'Learning Rate': [learning_rates],\n",
    "                    'Momentum': [momentum],\n",
    "                    'Weight Decay': [weight_decay],\n",
    "                    'Optimizer': [optimizer_class],\n",
    "                    'Patience': [patience],\n",
    "                    'Scheduler': [schedulers],\n",
    "                    'Loss Function': [loss_function]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "                results_df.to_csv(\"check_results.csv\", index=False)\n",
    "                print(\"Saved results to CSV for checking.\")   \n",
    "        \n",
    "        logging.info(f\"Finished trial {trial+1}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in trial {trial+1} with params: {params}. Error: {str(e)}\")\n",
    "        continue\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_hyperparameters)\n",
    "print(\"Best Training Accuracy: {:.2f}%\".format(best_train_accuracy / len(train_loader) * 100))\n",
    "print(\"Best Validation Accuracy: {:.2f}%\".format(best_val_accuracy / len(validation_loader) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# # Print the best hyperparameters and accuracy\n",
    "# print(\"\\nBest Hyperparameters:\")\n",
    "# print(best_hyperparameters)\n",
    "# print(\"Best Training Accuracy: {:.2f}%\".format(best_train_accuracy / len(train_loader) * 100))\n",
    "# print(\"Best Validation Accuracy: {:.2f}%\".format(best_val_accuracy / len(validation_loader) * 100))\n",
    "\n",
    "# # Plotting the training and validation loss\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.plot(avg_train_losses, label=\"Training Loss\", color=\"blue\")\n",
    "# plt.plot(avg_val_losses, label=\"Validation Loss\", color=\"red\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plotting the training and validation accuracies\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"Training and Validation Accuracy\")\n",
    "# plt.plot([100 * acc for acc in avg_train_accuracies], label=\"Training Accuracy\", color=\"blue\")\n",
    "# plt.plot([100 * acc for acc in avg_val_accuracies], label=\"Validation Accuracy\", color=\"red\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Accuracy (%)\")\n",
    "# plt.legend()\n",
    "# plt.ylim(0, 100)  # Set y-axis to show percentages from 0 to 100\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def test(split):\n",
    "    network.eval()\n",
    "    y_true = torch.tensor([], device=device)\n",
    "    y_score = torch.tensor([], device=device)\n",
    "\n",
    "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.cpu().detach().numpy()\n",
    "\n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "\n",
    "        #print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "    return (split, *metrics), y_true, y_score\n",
    "\n",
    "\n",
    "print('==> Evaluating ...')\n",
    "# test('train')\n",
    "# test('test')\n",
    "train_result, _, _ = test(\"train\")  # Unpack only the first returned value\n",
    "print('%s  auc: %.3f  acc:%.3f' % train_result)\n",
    "test_result, _, _ = test(\"test\")  # Unpack only the first returned value\n",
    "print('%s  auc: %.3f  acc:%.3f' % test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade torcheval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAUPRC\n",
    "import torch\n",
    "\n",
    "_, train_true, train_scores = test('train')\n",
    "_, test_true, test_scores = test('test')\n",
    "\n",
    "train_scores = torch.tensor(train_scores, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_true = torch.tensor(train_true, device='cuda' if torch.cuda.is_available() else 'cpu').long().squeeze()  # Ensure labels are long type\n",
    "test_scores = torch.tensor(test_scores, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_true = torch.tensor(test_true, device='cuda' if torch.cuda.is_available() else 'cpu').long().squeeze()\n",
    "# Assuming num_classes is the actual number of classes\n",
    "num_classes = 2# len(torch.unique(torch.tensor(train_true)))  # Update based on your labels\n",
    "\n",
    "# Initialize the Multiclass AUPRC metric\n",
    "metric_train = MulticlassAUPRC(num_classes=n_classes)\n",
    "metric_train.update(train_scores, train_true)\n",
    "\n",
    "metric_test = MulticlassAUPRC(num_classes=n_classes)\n",
    "metric_test.update(test_scores, test_true)\n",
    "\n",
    "# Compute the final AUPRC\n",
    "train_auprc_result = metric_train.compute()\n",
    "test_auprc_result = metric_test.compute()\n",
    "\n",
    "print(\"Train AUPRC result:\", train_auprc_result)\n",
    "print(\"Test AUPRC result:\", test_auprc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Precision, Recall & F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "train_true = train_true.cpu()\n",
    "train_scores = train_scores.cpu()\n",
    "test_true = test_true.cpu()\n",
    "test_scores = test_scores.cpu()\n",
    "\n",
    "train_precision = precision_score(train_true, train_scores.argmax(dim=1), average='weighted')\n",
    "test_precision = precision_score(test_true, test_scores.argmax(dim=1), average='weighted')\n",
    "\n",
    "print(\"Train Precision Score:\", train_precision)\n",
    "print(\"Test Precision Score:\", test_precision)\n",
    "\n",
    "print()\n",
    "\n",
    "train_recall = recall_score(train_true, train_scores.argmax(dim=1), average='weighted')\n",
    "test_recall = recall_score(test_true, test_scores.argmax(dim=1), average='weighted')\n",
    "\n",
    "print(\"Train Recall Score:\", train_recall)\n",
    "print(\"Test Recall Score:\", test_recall)\n",
    "\n",
    "print() \n",
    "\n",
    "train_f1 = f1_score(train_true, train_scores.argmax(dim=1), average='weighted')\n",
    "test_f1 = f1_score(test_true, test_scores.argmax(dim=1), average='weighted')\n",
    "\n",
    "print(\"Train F1 Score:\", train_f1)\n",
    "print(\"Test F1 Score:\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_fpr, train_tpr, train_thresholds = metrics.roc_curve(train_true, train_scores[:, 1])\n",
    "train_roc_auc = metrics.auc(train_fpr, train_tpr)\n",
    "\n",
    "test_fpr, test_tpr, test_thresholds = metrics.roc_curve(test_true, test_scores[:, 1])\n",
    "test_roc_auc = metrics.auc(test_fpr, test_tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_fpr, train_tpr, label=f'Train ROC curve (area = {train_roc_auc:.2f})')\n",
    "plt.plot(test_fpr, test_tpr, label=f'Test ROC curve (area = {test_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], \"b--\")  # Dashed diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_true.shape)\n",
    "print(train_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "confusionMatrix = confusion_matrix(train_true, train_scores)\n",
    "labels = ['Malignant', 'Benign'] # CHECK LABELS\n",
    "display_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix, display_labels=labels)\n",
    "display_confusion_matrix.plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume 'model' is your trained model\n",
    "network.eval()\n",
    "\n",
    "# Assuming you have a DataLoader for your test data\n",
    "# For a specific image, you might load it directly as shown below\n",
    "image, label = pil_dataset[20]\n",
    "\n",
    "# Transform the image according to your model's expected input\n",
    "# This should match your training transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Example size, adjust as necessary\n",
    "    transforms.ToTensor(),\n",
    "    # Include normalization if used during training\n",
    "])\n",
    "\n",
    "# Apply transformation\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move image to the same device as your model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image = image.to(device)\n",
    "model = network.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "\n",
    "# Assuming the output is logits; apply softmax for probabilities\n",
    "probabilities = torch.softmax(output, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "# Assuming class 0 is 'benign' and class 1 is 'malignant'\n",
    "classes = ['benign', 'malignant']\n",
    "predicted_class = classes[probabilities.argmax()]\n",
    "confidence = probabilities.max()\n",
    "\n",
    "print(f\"Predicted class: {predicted_class} with confidence {confidence:.2f}\")\n",
    "\n",
    "\n",
    "image_np = image.squeeze().cpu().numpy()\n",
    "\n",
    "# If the image is grayscale (C, H, W) where C = 1, we convert it to (H, W) for matplotlib\n",
    "if image_np.shape[0] == 1:  # Grayscale image, single channel\n",
    "    image_np = image_np.squeeze(0)  # Now shape is (H, W)\n",
    "elif image_np.shape[0] == 3:  # If it's a 3-channel image\n",
    "    # Convert from (C, H, W) to (H, W, C) for RGB images\n",
    "    image_np = np.transpose(image_np, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_np, cmap='gray' if image_np.ndim == 2 else None)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
